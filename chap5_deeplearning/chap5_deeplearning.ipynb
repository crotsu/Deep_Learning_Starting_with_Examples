{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第5章 再び，Deep Learning！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フレームワーク(TensorFlow + Keras)を使ってXORを学習してみよう！\n",
    "ここまで見てきたように，頑張れば自力でニューラルネットワークを実装することができる．  \n",
    "しかし，とても大変だったことがわかると思う．  \n",
    "さらに，今，Deep Learningの研究を行っている人が多数いる．  \n",
    "その人達と成果物を共有しようとするとなると，各自が自作したプログラムでは議論が難しい．  \n",
    "\n",
    "そこで，Deep Learningを動かす枠組み（フレームワーク）が多く開発されている．  \n",
    "ここでは，それらの一つであるGoogleが開発したTensorFlowを紹介する．  \n",
    "TensorFlowはニューラルネットワークを動かすというよりは，テンソル（3次元以上の多次元行列）の演算を行うために開発されたものである．  \n",
    "もちろん，Deep Learningのために開発されたのであるが，ニューラルネットワークは行列の演算を多く行う．  \n",
    "そのため，行列演算のために，しかも並列計算が可能になるように開発されたものがTensorFlowである．  \n",
    "\n",
    "さらに，　KerasはTensorFlowのフロントエンドであり，Deep Learningのモデルを短い記述で実装できる．  \n",
    "一般的に，TensorFlowでDeep Learningを実装しようとすると，Kerasを用いる．  \n",
    "\n",
    "TensorFlow + Kerasを使えば簡単に実装できる．  \n",
    "ニューラルネットワークの構造を変えたり，活性化関数を変更したり，最適化のアルゴリズムを変更したり，とにかくいろいろできる．  \n",
    "さらに，グラフを表示したり，ネットワークの出力を可視化したり，とにかく機能が豊富である．  \n",
    "\n",
    "講義の最初に動作させた画像認識のプログラムを例に説明する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:01:16.658995: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step\n",
      "[[9.0599060e-06]\n",
      " [9.9999309e-01]\n",
      " [9.9999452e-01]\n",
      " [3.7550926e-06]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-28 14:01:33.450707: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow をセットアップする\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# トレーニングデータ\n",
    "# XOR\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# モデル設定（階層型）\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# 入力層 - 隠れ層（入力2，中間2）\n",
    "model.add(tf.keras.layers.Dense(input_dim=2, units=2))\n",
    "model.add(tf.keras.layers.Activation('sigmoid'))\n",
    "\n",
    "# 隠れ層 - 出力層（出力1）\n",
    "model.add(tf.keras.layers.Dense(units=1))\n",
    "model.add(tf.keras.layers.Activation('linear'))\n",
    "\n",
    "# 最適化 stochastic gradient descent\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "# モデル学習\n",
    "model.fit(X, Y, epochs=4000, verbose=0)\n",
    "\n",
    "# 学習結果の確認\n",
    "print(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重みを確認する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベクトル・行列演算で計算してみる．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XORの最初のパターン[0,0]を入力して，重みとの積を計算する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0\n",
    "a = np.dot(model.get_weights()[0].T,X[p])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それに閾値を足す．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a+model.get_weights()[1]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイド関数に通す． これで中間層2個の出力値を得る．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = tf.math.sigmoid(b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同様に出力層の出力を計算する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.dot(model.get_weights()[2].T,c)+model.get_weights()[3]\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでXORの1番目のパターン[0,0]を入力して，0．0が出力されていることがわかる．  \n",
    "フレームワークTensowFlowを用いても，やっている計算は同じであることがわかる．  \n",
    "\n",
    "どうように4パターンを入力し，そのときに予測を出力する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(4):\n",
    "    out1 = tf.math.sigmoid(np.dot(model.get_weights()[0].T,X[p])+model.get_weights()[1])\n",
    "    out2 = np.dot(model.get_weights()[2].T,out1)+model.get_weights()[3]\n",
    "    print(out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの基礎理論を理解した上で，もう一度，文字認識をやってみよう．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 意味を理解しながら，一つずつ動かしてみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow をセットアップする\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データであるMNISTデータを読み込む．  \n",
    "もともとの文字のデータは0から255のグレースケールだが，255.0で割ることで，0．0から1．0に変換している．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST（0から9の数字画像）セットを読み込む\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習データを眺めてみる．  \n",
    "トレーニングデータは60000個，テストデータは10000個である．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次にデータの中身を覗いてみよう．  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これではさっぱりわからいので，トレーニングデータの最初の文字を表示してみよう．  \n",
    "また，画像で表示してみると「5」に見える．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x_train[0]:\n",
    "    for j in i:\n",
    "        print('{:.1f}'.format(j), end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0] * 255, cmap=\"gray_r\")\n",
    "plt.show()\n",
    "\n",
    "# 一般的にグレースケールは0が黒，255が白だが，反転している．"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像サイズは28x28である．  \n",
    "これを1列に並べて，784次元の特徴ベクトルとして階層型ニューラルネットワークで学習させる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.shape(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 機械学習モデルを構築する\n",
    "Flattenは縦と横の画像を1列に並べる操作である．  \n",
    "Dropoutは学習中に20%の重みをランダムに削除して学習させている．  \n",
    "これにより汎化性能の向上が期待される．  \n",
    "最終的には0から9の10種の数字なので，出力層は10個のニューロンを持つことになる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 機械学習モデルを構築する\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの構成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "損失関数はクロスエントロピーを用いる．  \n",
    "0から9の数字を予測するため，出力層10個の各ニューロンの出力値が，0.0から1.0の確率値に対応している．  \n",
    "最適化はadamを用いる． (参考文献:[An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの構成\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまででニューラルネットワークのモデル構築ができた．  \n",
    "あとはバックプロパゲーションで学習させるだけである．  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習\n",
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習には用いなかったテストデータでモデルの評価を行う．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの評価を行う\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### テストデータに対する予測を行う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テストデータを入力したときに出力層10個のニューロンの値をみてみよう．  \n",
    "それぞれ確率の値となっているので，最大値のニューロンに該当する数字を予測した数字とする．  \n",
    "先頭5個のテストデータを入力して確認してみよう．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対する予測を行う\n",
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])\n",
    "\n",
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文字認識の結果を確認してみよう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "row = 3\n",
    "col = 4\n",
    "predictions = probability_model(x_test[:row*col])\n",
    "\n",
    "fig = plt.figure(figsize=(row, col))\n",
    "\n",
    "# 予測と正解を可視化して比べてみる\n",
    "fig.subplots_adjust(left=0, right=2, bottom=0.5, top=2, hspace=0.3, wspace=0.3)\n",
    "for index, prediction in enumerate(predictions):\n",
    "    ax = fig.add_subplot(row, col, index + 1)\n",
    "    ax.set_title(\"prediction:\"+str(np.argmax(prediction)))\n",
    "    plt.imshow(x_test[index] * 255, cmap=\"gray_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考文献\n",
    "- [初心者のための TensorFlow 2.0 入門](https://www.tensorflow.org/tutorials/quickstart/beginner?hl=ja)\n",
    "- [TensorFlowのチュートリアルをコメント付けながら実行してみた（初心者のための_TensorFlow_2_0_入門）](https://qiita.com/penpenta/items/ee45f58d416c656639aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# この後どうするか？\n",
    "- とにかく自分で動かしてみる．\n",
    "- 数学で表現されている基礎理論を理解する．\n",
    "- 実際に別の課題に取り組んで見る．\n",
    "- 1番大変なのは前処理！\n",
    "- 2番目に大変なのは良質のデータを大量に集めること！\n",
    "- 書籍やネットに多くの情報があるので取り組みやすい状況ではあるが，とにかく動かしてみることが一番大事"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[講義資料に戻る](https://github.com/crotsu/Deep_Learning_Starting_with_Examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このページは[このリンク](https://colab.research.google.com/github/crotsu/Deep_Learning_Starting_with_Examples/blob/main/chap5_deeplearning/chap5_deeplearning.ipynb)よりgoogle colaboratoryで動作させることができる．  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
